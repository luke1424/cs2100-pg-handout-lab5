Programming questions 2, 3, and 4 together comprise a small language model.
ChatGPT and Claude are large language models: they work like the model in this lab, but they use much more data and store much more information.

1. We suggested using the dataset of Olivia Rodrigo's song lyrics to train the small language model. How would it be different if we instead used a dataset of very serious legal documents? Or a dataset of your messages to your friends? How does the choice of dataset affect the output?
2. Search online to learn which dataset was used to train GPT. How might their choice of dataset affect the performance of the model?
3. There are social biases encoded in any language model, which it learned from the dataset on which it was trained. How might they affect the output of the model?
